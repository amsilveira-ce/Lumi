import 'dart:typed_data';
import 'package:google_generative_ai/google_generative_ai.dart';
import 'gemini_config.dart';
import 'gemini_stt_service.dart';
import 'gemini_tts_service.dart';

/// Servi√ßo de conversa√ß√£o por voz com IA
///
/// Integra STT (Speech-to-Text) + LLM + TTS (Text-to-Speech)
/// para criar uma experi√™ncia completa de conversa√ß√£o por voz
class VoiceChatService {
  final GeminiSTTService _sttService = GeminiSTTService();
  final GeminiTTSService _ttsService = GeminiTTSService();

  // Hist√≥rico de conversa√ß√£o
  final List<Content> _conversationHistory = [];

  // Estado
  bool _isProcessing = false;
  bool _isSpeaking = false;
  String? _lastUserMessage;
  String? _lastAIResponse;

  /// Getter para verificar se est√° processando
  bool get isProcessing => _isProcessing;

  /// Getter para verificar se est√° falando
  bool get isSpeaking => _isSpeaking;

  /// Getter para √∫ltima mensagem do usu√°rio
  String? get lastUserMessage => _lastUserMessage;

  /// Getter para √∫ltima resposta da IA
  String? get lastAIResponse => _lastAIResponse;

  /// Getter para hist√≥rico
  List<Content> get conversationHistory => List.unmodifiable(_conversationHistory);

  /// Processa √°udio do usu√°rio e retorna resposta falada
  ///
  /// Fluxo: √Åudio ‚Üí STT ‚Üí LLM ‚Üí TTS ‚Üí √Åudio
  Future<String> processVoiceInput(Uint8List audioBytes, {String mimeType = 'audio/wav'}) async {
    if (_isProcessing) {
      throw Exception('Already processing a message');
    }

    _isProcessing = true;

    try {
      // 1. STT: Converter √°udio em texto
      print('üé§ Step 1: Transcribing audio...');
      final userText = await _sttService.transcribe(audioBytes, mimeType: mimeType);
      _lastUserMessage = userText;
      print('üìù User said: $userText');

      // 2. LLM: Gerar resposta da IA
      print('ü§ñ Step 2: Generating AI response...');
      final aiResponse = await _generateAIResponse(userText);
      _lastAIResponse = aiResponse;
      print('üí≠ AI response: $aiResponse');

      // 3. TTS: Converter resposta em √°udio e reproduzir
      print('üîä Step 3: Speaking response...');
      _isSpeaking = true;

      try {
        await _ttsService.speak(aiResponse, voiceName: 'Zephyr');

        // Aguardar um pouco ap√≥s terminar de falar
        await Future.delayed(const Duration(milliseconds: 500));
      } finally {
        _isSpeaking = false;
      }

      return aiResponse;

    } catch (e) {
      print('‚ùå Error in voice chat: $e');
      rethrow;
    } finally {
      _isProcessing = false;
    }
  }

  /// Gera resposta da IA usando Gemini LLM
  Future<String> _generateAIResponse(String userMessage) async {
    if (!GeminiConfig.isInitialized) {
      throw Exception('GeminiConfig not initialized');
    }

    try {
      final model = GeminiConfig.model;

      // Adicionar mensagem do usu√°rio ao hist√≥rico
      _conversationHistory.add(Content.text(userMessage));

      // Gerar resposta
      final response = await model.generateContent(_conversationHistory);

      final aiText = response.text ?? 'Desculpe, n√£o consegui gerar uma resposta.';

      // Adicionar resposta da IA ao hist√≥rico
      _conversationHistory.add(Content.model([TextPart(aiText)]));

      return aiText;

    } catch (e) {
      print('Error generating AI response: $e');
      return 'Desculpe, ocorreu um erro ao processar sua mensagem.';
    }
  }

  /// Envia mensagem de texto (sem √°udio) e recebe resposta falada
  Future<String> sendTextMessage(String message) async {
    if (_isProcessing) {
      throw Exception('Already processing a message');
    }

    _isProcessing = true;

    try {
      _lastUserMessage = message;
      print('üìù User text: $message');

      // Gerar resposta da IA
      print('ü§ñ Generating AI response...');
      final aiResponse = await _generateAIResponse(message);
      _lastAIResponse = aiResponse;
      print('üí≠ AI response: $aiResponse');

      // Falar resposta
      print('üîä Speaking response...');
      _isSpeaking = true;

      try {
        await _ttsService.speak(aiResponse, voiceName: 'Zephyr');

        // Aguardar um pouco ap√≥s terminar de falar
        await Future.delayed(const Duration(milliseconds: 500));
      } finally {
        _isSpeaking = false;
      }

      return aiResponse;

    } catch (e) {
      print('‚ùå Error in text chat: $e');
      rethrow;
    } finally {
      _isProcessing = false;
    }
  }

  /// Define o contexto/personalidade da IA
  void setSystemContext(String context) {
    _conversationHistory.clear();

    // Adicionar como system instruction (user + model response para simular)
    _conversationHistory.add(Content.text(context));
    _conversationHistory.add(Content.model([
      TextPart('Entendido! Estou pronta para conversar como Lumi.')
    ]));
  }

  /// Limpa o hist√≥rico de conversa√ß√£o
  void clearHistory() {
    _conversationHistory.clear();
    _lastUserMessage = null;
    _lastAIResponse = null;
  }

  /// Para a reprodu√ß√£o de √°udio atual
  Future<void> stopSpeaking() async {
    await _ttsService.stop();
  }

  /// Limpa recursos
  void dispose() {
    _ttsService.dispose();
  }
}
